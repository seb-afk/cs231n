{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "def svm_loss_naive(W, X, y, reg):\n",
    "  \"\"\"\n",
    "  Structured SVM loss function, naive implementation (with loops).\n",
    "\n",
    "  Inputs have dimension D, there are C classes, and we operate on minibatches\n",
    "  of N examples.\n",
    "\n",
    "  Inputs:\n",
    "  - W: A numpy array of shape (D, C) containing weights.\n",
    "  - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
    "  - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "    that X[i] has label c, where 0 <= c < C.\n",
    "  - reg: (float) regularization strength\n",
    "\n",
    "  Returns a tuple of:\n",
    "  - loss as single float\n",
    "  - gradient with respect to weights W; an array of same shape as W\n",
    "  \"\"\"\n",
    "  dW = np.zeros(W.shape) # initialize the gradient as zero\n",
    "\n",
    "  # compute the loss and the gradient\n",
    "  num_classes = W.shape[1]\n",
    "  num_train = X.shape[0]\n",
    "  loss = 0.0\n",
    "  for i in range(num_train):  # Loop through training examples\n",
    "    scores = X[i].dot(W)  # The class score is a dot product between X and W\n",
    "    correct_class_score = scores[y[i]] # Score assigned to the correct class\n",
    "    for j in range(num_classes):  # Compute hinge loss by looping though classes\n",
    "      if j == y[i]:  # no need to compute loss for correct class\n",
    "        continue\n",
    "      margin = scores[j] - correct_class_score + 1 # note delta = 1\n",
    "      if margin > 0:  # we only add to the loss if margin exceed 0\n",
    "        loss += margin\n",
    "        dW[:,j] += X[i] \n",
    "        dW[:,y[i]] -= X[i] \n",
    "\n",
    "  # Right now the loss is a sum over all training examples, but we want it\n",
    "  # to be an average instead so we divide by num_train.\n",
    "  loss /= num_train\n",
    "  dW /= num_train\n",
    "\n",
    "  # Add regularization to the loss.\n",
    "  loss += 0.5 * reg * np.sum(W * W) \n",
    "  dW += reg * W\n",
    "  return loss, dW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=2\n",
    "D=3\n",
    "C=3\n",
    "targets = [0,0]\n",
    "delta = 1\n",
    "reg = 0\n",
    "\n",
    "# Random data generation\n",
    "np.random.seed(123)\n",
    "W = np.random.randn(D,C)\n",
    "# X = np.random.randn(N,D)\n",
    "X = np.array([[1,2,3],[4,5,6]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[0]\n",
    "score_mat = X.dot(W)\n",
    "correct_class_scores = score_mat[range(N),targets].reshape(N,1)\n",
    "margins = score_mat - correct_class_scores + delta\n",
    "margins[range(N),targets] = 0\n",
    "margins = np.clip(margins, 0, None)\n",
    "dataloss = np.mean(np.sum(margins, axis=1))\n",
    "regularizationloss = 0.5 * reg * np.sum(W*W)\n",
    "totalloss = dataloss + regularizationloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = deepcopy(margins)\n",
    "mask[mask > 0] = 1\n",
    "dW = np.zeros(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]] \n",
      "\n",
      " [[ 0.         10.93166482 19.76191811]\n",
      " [ 0.         25.9569762  44.41878567]] \n",
      "\n",
      " [[-1.0856306   0.99734545  0.2829785 ]\n",
      " [-1.50629471 -0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263  1.26593626]]\n"
     ]
    }
   ],
   "source": [
    "print(X,\"\\n\\n\", margins,\"\\n\\n\",W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_sum = np.sum(mask, axis=1)\n",
    "row_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.534672398328325 [[-5.   2.5  2.5]\n",
      " [-7.   3.5  3.5]\n",
      " [-9.   4.5  4.5]]\n"
     ]
    }
   ],
   "source": [
    "mask[range(N), targets] -= row_sum.T\n",
    "dW = np.dot(X.T, mask) / N\n",
    "dW += reg * W\n",
    "print(totalloss, dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.53467239832832, array([[-5. ,  2.5,  2.5],\n",
       "        [-7. ,  3.5,  3.5],\n",
       "        [-9. ,  4.5,  4.5]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_loss_naive(W,X, targets, reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "N_test = 5\n",
    "D = 3\n",
    "np.random.seed(123)\n",
    "X_train = np.random.randint(10,size=(N, D))\n",
    "y_train = np.random.randint(1,size=(N,1))\n",
    "X_test = np.random.randint(10,size=(N_test, D))\n",
    "# Identity = np.tile(np.identity(N),N_test).T\n",
    "# tmp1 = Identity.dot(X_train).reshape(N_test,N,D)\n",
    "# tmp2 = X_test.reshape(N_test,1,D)\n",
    "# distances = tmp1 - tmp2\n",
    "# np.sqrt(np.sum(distances**2,axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.34846923,  9.43398113,  5.38516481, 10.77032961, 10.86278049,\n",
       "         7.07106781,  6.164414  ,  6.08276253,  2.23606798,  4.35889894],\n",
       "       [ 4.24264069,  6.70820393,  5.        , 10.67707825, 10.19803903,\n",
       "         5.47722558,  2.82842712,  3.31662479,  1.73205081,  3.        ],\n",
       "       [ 6.40312424,  9.48683298,  1.41421356,  8.66025404,  9.43398113,\n",
       "         3.        ,  6.40312424,  4.24264069,  3.16227766,  6.63324958],\n",
       "       [ 6.164414  ,  8.06225775,  5.74456265, 10.48808848, 10.19803903,\n",
       "         7.07106781,  4.89897949,  5.19615242,  1.73205081,  3.60555128],\n",
       "       [ 2.        ,  3.31662479,  8.54400375,  9.2736185 ,  7.61577311,\n",
       "         7.48331477,  4.24264069,  3.60555128,  7.28010989,  8.30662386]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distances = X_train-X_test.reshape(N_test,1,D)\n",
    "# distances.shape\n",
    "np.sqrt(np.sum((X_train-X_test.reshape(N_test,1,D))**2,axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.34846923,  4.24264069,  6.40312424,  6.164414  ,  2.        ],\n",
       "       [ 9.43398113,  6.70820393,  9.48683298,  8.06225775,  3.31662479],\n",
       "       [ 5.38516481,  5.        ,  1.41421356,  5.74456265,  8.54400375],\n",
       "       [10.77032961, 10.67707825,  8.66025404, 10.48808848,  9.2736185 ],\n",
       "       [10.86278049, 10.19803903,  9.43398113, 10.19803903,  7.61577311],\n",
       "       [ 7.07106781,  5.47722558,  3.        ,  7.07106781,  7.48331477],\n",
       "       [ 6.164414  ,  2.82842712,  6.40312424,  4.89897949,  4.24264069],\n",
       "       [ 6.08276253,  3.31662479,  4.24264069,  5.19615242,  3.60555128],\n",
       "       [ 2.23606798,  1.73205081,  3.16227766,  1.73205081,  7.28010989],\n",
       "       [ 4.35889894,  3.        ,  6.63324958,  3.60555128,  8.30662386]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term1 = np.sum(X_train**2, axis=1).reshape(-1,1)\n",
    "term2 = 2*X_train.dot(X_test.T)\n",
    "term3 = np.sum(X_test**2, axis=1)\n",
    "distances = np.sqrt(term1 - term2 + term3)\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 44]\n",
      " [ 91]\n",
      " [ 37]\n",
      " [ 82]\n",
      " [ 90]\n",
      " [ 16]\n",
      " [ 66]\n",
      " [ 29]\n",
      " [ 69]\n",
      " [113]] \n",
      "\n",
      " [[ 44]\n",
      " [ 91]\n",
      " [ 37]\n",
      " [ 82]\n",
      " [ 90]\n",
      " [ 16]\n",
      " [ 66]\n",
      " [ 29]\n",
      " [ 69]\n",
      " [113]]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(X_train[:,np.newaxis,:]**2, axis=2),\n",
    "      \"\\n\\n\",\n",
    "       np.sum(X_train**2, axis=1).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_nearest_neighbor import KNearestNeighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.34846923,  9.43398113,  5.38516481, 10.77032961, 10.86278049,\n",
       "         7.07106781,  6.164414  ,  6.08276253,  2.23606798,  4.35889894],\n",
       "       [ 4.24264069,  6.70820393,  5.        , 10.67707825, 10.19803903,\n",
       "         5.47722558,  2.82842712,  3.31662479,  1.73205081,  3.        ],\n",
       "       [ 6.40312424,  9.48683298,  1.41421356,  8.66025404,  9.43398113,\n",
       "         3.        ,  6.40312424,  4.24264069,  3.16227766,  6.63324958],\n",
       "       [ 6.164414  ,  8.06225775,  5.74456265, 10.48808848, 10.19803903,\n",
       "         7.07106781,  4.89897949,  5.19615242,  1.73205081,  3.60555128],\n",
       "       [ 2.        ,  3.31662479,  8.54400375,  9.2736185 ,  7.61577311,\n",
       "         7.48331477,  4.24264069,  3.60555128,  7.28010989,  8.30662386]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)\n",
    "classifier.compute_distances_one_loop(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 7.34846923,  4.24264069,  6.40312424,  6.164414  ,  2.        ],\n",
       "        [ 9.43398113,  6.70820393,  9.48683298,  8.06225775,  3.31662479],\n",
       "        [ 5.38516481,  5.        ,  1.41421356,  5.74456265,  8.54400375],\n",
       "        [10.77032961, 10.67707825,  8.66025404, 10.48808848,  9.2736185 ]]),\n",
       " array([[10.86278049, 10.19803903,  9.43398113, 10.19803903,  7.61577311],\n",
       "        [ 7.07106781,  5.47722558,  3.        ,  7.07106781,  7.48331477],\n",
       "        [ 6.164414  ,  2.82842712,  6.40312424,  4.89897949,  4.24264069]]),\n",
       " array([[6.08276253, 3.31662479, 4.24264069, 5.19615242, 3.60555128],\n",
       "        [2.23606798, 1.73205081, 3.16227766, 1.73205081, 7.28010989],\n",
       "        [4.35889894, 3.        , 6.63324958, 3.60555128, 8.30662386]])]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_split(distances, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0} {1, 2, 3, 4}\n",
      "[0]\n",
      "[1 2 3 4]\n",
      "{1} {0, 2, 3, 4}\n",
      "[1]\n",
      "[0 2 3 4]\n",
      "{2} {0, 1, 3, 4}\n",
      "[2]\n",
      "[0 1 3 4]\n",
      "{3} {0, 1, 2, 4}\n",
      "[3]\n",
      "[0 1 2 4]\n",
      "{4} {0, 1, 2, 3}\n",
      "[4]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "for fold in range(num_folds):\n",
    "    val_idx = set([fold])\n",
    "    train_idx = set([i for i in range(num_folds)]) - val_idx\n",
    "    print(val_idx, train_idx)\n",
    "    print(np.array([0, 1,2,3,4])[list(val_idx)])\n",
    "    print(np.array([0,1,2,3,4])[list(train_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,1])\n",
    "b = np.array([1,1,1])\n",
    "np.mean(a == b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) (1, 2)\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[1,0],[0,1], [1,1]]).T # shape (D,C)\n",
    "X = np.array([[1,2]]) # shape (N,D)\n",
    "y = 1\n",
    "num_classes = W.shape[1]\n",
    "print(W.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = X.dot(W)  #shape (N,C)\n",
    "scores = scores + np.log(num_classes)\n",
    "scores_exp = np.exp(scores)\n",
    "scores_norm = scores_exp / np.sum(scores_exp)\n",
    "loss = -np.log(scores_norm.ravel()[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4076059644443804"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
